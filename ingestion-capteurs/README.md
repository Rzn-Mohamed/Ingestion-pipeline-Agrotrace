# ğŸ“¡ IngestionCapteurs - Microservice de Collecte de DonnÃ©es IoT

## ğŸ¯ Vue d'ensemble

**IngestionCapteurs** est le premier microservice de la plateforme Agrotrace. Il est responsable de la collecte, validation et harmonisation des donnÃ©es provenant des capteurs IoT agricoles et des stations mÃ©tÃ©orologiques.

### RÃ´le Principal
Collecter les donnÃ©es en temps rÃ©el issues des capteurs IoT (humiditÃ© du sol, tempÃ©rature, luminositÃ©, pH) et des stations mÃ©tÃ©orologiques, puis les diffuser vers les autres microservices de la plateforme.

### FonctionnalitÃ©s ClÃ©s
- âœ… **Ingestion de donnÃ©es** : RÃ©ception de flux JSON via API REST
- âœ… **Validation et harmonisation** : VÃ©rification de la cohÃ©rence des donnÃ©es
- âœ… **Diffusion temps rÃ©el** : Publication des donnÃ©es vers Kafka
- âœ… **Stockage temporel** : Persistance dans TimescaleDB
- âœ… **TraÃ§abilitÃ©** : Horodatage prÃ©cis et identification des capteurs

---

## ğŸ—ï¸ Architecture

![Architecture du microservice IngestionCapteurs](micro-service1.png)

Le microservice suit le flux suivant :
1. **Capteurs IoT** envoient des donnÃ©es JSON via HTTP
2. **FastAPI** reÃ§oit et valide les donnÃ©es avec Pydantic
3. Les donnÃ©es sont stockÃ©es dans **TimescaleDB** pour l'historique
4. **Kafka Producer** publie les donnÃ©es vers Kafka pour le traitement temps rÃ©el
5. Le microservice de **PrÃ©traitement** consomme les messages Kafka

---

## ğŸ“Š ModÃ¨le de DonnÃ©es

### Structure CapteurData

```json
{
  "capteur_id": "SENSOR_001",
  "timestamp": "2025-11-01T14:30:00Z",
  "temperature": 22.5,
  "humidite": 65.0,
  "humidite_sol": 45.0,
  "niveau_ph": 6.8,
  "luminosite": 850.0
}
```

### Champs

| Champ | Type | Obligatoire | Description |
|-------|------|-------------|-------------|
| `capteur_id` | string | âœ… | Identifiant unique du capteur |
| `timestamp` | datetime | âœ… | Horodatage de la mesure (ISO 8601) |
| `temperature` | float | âŒ | TempÃ©rature en Â°C |
| `humidite` | float | âŒ | HumiditÃ© de l'air en % |
| `humidite_sol` | float | âŒ | HumiditÃ© du sol en % |
| `niveau_ph` | float | âŒ | Niveau de pH du sol (0-14) |
| `luminosite` | float | âŒ | LuminositÃ© en lux |

---

## ğŸš€ Installation et DÃ©marrage

### PrÃ©requis

- Docker & Docker Compose
- Python 3.9+
- Git

### 1. Cloner le Repository

```bash
git clone https://github.com/Rzn-Mohamed/Ingestion-pipeline-Agrotrace.git
cd Ingestion-pipeline-Agrotrace
```

### 2. DÃ©marrer l'Infrastructure

```bash
# DÃ©marrer Kafka, Zookeeper et TimescaleDB
docker-compose up -d
```

VÃ©rifier que les services sont actifs :
```bash
docker-compose ps
```

### 3. Configuration de l'Environnement

CrÃ©er un fichier `.env` dans le dossier `ingestion-capteurs/` :

```env
# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC=capteurs-data

# TimescaleDB Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=agrotrace_db
DB_USER=admin
DB_PASSWORD=password

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
```

### 4. Installer les DÃ©pendances

```bash
cd ingestion-capteurs
python -m venv env
.\env\Scripts\Activate.ps1  # Windows PowerShell
pip install -r requirements.txt
```

### 5. Lancer le Microservice

```bash
# Mode dÃ©veloppement
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Ou avec Docker
docker build -t ingestion-capteurs .
docker run -p 8000:8000 ingestion-capteurs
```

---

## ğŸ“¡ API REST

### Base URL
```
http://localhost:8000
```

### Endpoints

#### 1. Health Check
```http
GET /health
```

**RÃ©ponse :**
```json
{
  "status": "healthy",
  "service": "IngestionCapteurs",
  "timestamp": "2025-11-01T14:30:00Z"
}
```

#### 2. IngÃ©rer des DonnÃ©es de Capteur
```http
POST /api/v1/capteurs/ingest
Content-Type: application/json
```

**Corps de la requÃªte :**
```json
{
  "capteur_id": "SENSOR_001",
  "timestamp": "2025-11-01T14:30:00Z",
  "temperature": 22.5,
  "humidite": 65.0,
  "humidite_sol": 45.0,
  "niveau_ph": 6.8,
  "luminosite": 850.0
}
```

**RÃ©ponse (201 Created) :**
```json
{
  "status": "success",
  "message": "DonnÃ©es ingÃ©rÃ©es avec succÃ¨s",
  "capteur_id": "SENSOR_001",
  "timestamp": "2025-11-01T14:30:00Z"
}
```

#### 3. Ingestion par Lot
```http
POST /api/v1/capteurs/ingest/batch
Content-Type: application/json
```

**Corps de la requÃªte :**
```json
{
  "data": [
    {
      "capteur_id": "SENSOR_001",
      "timestamp": "2025-11-01T14:30:00Z",
      "temperature": 22.5,
      "humidite_sol": 45.0
    },
    {
      "capteur_id": "SENSOR_002",
      "timestamp": "2025-11-01T14:30:05Z",
      "temperature": 23.0,
      "luminosite": 900.0
    }
  ]
}
```

#### 4. RÃ©cupÃ©rer les DonnÃ©es d'un Capteur
```http
GET /api/v1/capteurs/{capteur_id}/data?start_date=2025-11-01&end_date=2025-11-02
```

**ParamÃ¨tres :**
- `capteur_id` : Identifiant du capteur
- `start_date` : Date de dÃ©but (YYYY-MM-DD)
- `end_date` : Date de fin (YYYY-MM-DD)

---

## ğŸ§ª Simulation de Capteurs IoT

Un script de simulation est fourni pour gÃ©nÃ©rer des donnÃ©es rÃ©alistes de capteurs.

### Utilisation du Simulateur

```bash
cd ingestion-capteurs
python simulator/iot_simulator.py
```

### Options du Simulateur

```bash
# Simuler 5 capteurs envoyant des donnÃ©es toutes les 10 secondes
python simulator/iot_simulator.py --capteurs 5 --interval 10

# Mode batch : envoyer 100 mesures par capteur
python simulator/iot_simulator.py --capteurs 3 --mode batch --count 100

# Avec des paramÃ¨tres personnalisÃ©s
python simulator/iot_simulator.py --capteurs 2 --temp-min 15 --temp-max 30 --interval 5
```

### ParamÃ¨tres Disponibles

| ParamÃ¨tre | Description | DÃ©faut |
|-----------|-------------|--------|
| `--capteurs` | Nombre de capteurs Ã  simuler | 3 |
| `--interval` | Intervalle entre envois (secondes) | 15 |
| `--mode` | Mode : `realtime` ou `batch` | realtime |
| `--count` | Nombre de mesures en mode batch | 50 |
| `--temp-min` | TempÃ©rature minimale (Â°C) | 10 |
| `--temp-max` | TempÃ©rature maximale (Â°C) | 35 |
| `--api-url` | URL de l'API | http://localhost:8000 |

---

## ğŸ—„ï¸ Base de DonnÃ©es TimescaleDB

### Initialisation de la Base

```sql
-- Connexion Ã  la base
psql -h localhost -p 5432 -U admin -d agrotrace_db

-- CrÃ©er l'extension TimescaleDB
CREATE EXTENSION IF NOT EXISTS timescaledb;

-- CrÃ©er la table des donnÃ©es capteurs
CREATE TABLE capteurs_data (
    time TIMESTAMPTZ NOT NULL,
    capteur_id TEXT NOT NULL,
    temperature DOUBLE PRECISION,
    humidite DOUBLE PRECISION,
    humidite_sol DOUBLE PRECISION,
    niveau_ph DOUBLE PRECISION,
    luminosite DOUBLE PRECISION
);

-- Convertir en hypertable (optimisÃ©e pour les sÃ©ries temporelles)
SELECT create_hypertable('capteurs_data', 'time');

-- CrÃ©er un index sur capteur_id
CREATE INDEX idx_capteur_id ON capteurs_data (capteur_id, time DESC);
```

### RequÃªtes Utiles

```sql
-- DonnÃ©es des derniÃ¨res 24 heures
SELECT * FROM capteurs_data
WHERE time > NOW() - INTERVAL '24 hours'
ORDER BY time DESC;

-- Moyenne horaire par capteur
SELECT 
    time_bucket('1 hour', time) AS hour,
    capteur_id,
    AVG(temperature) as temp_moy,
    AVG(humidite_sol) as hum_sol_moy
FROM capteurs_data
WHERE time > NOW() - INTERVAL '7 days'
GROUP BY hour, capteur_id
ORDER BY hour DESC;
```

---

## ğŸ”§ Technologies UtilisÃ©es

| Technologie | Version | RÃ´le |
|-------------|---------|------|
| **FastAPI** | 0.120+ | Framework API REST |
| **Uvicorn** | 0.38+ | Serveur ASGI |
| **Pydantic** | 2.12+ | Validation des donnÃ©es |
| **Confluent Kafka** | 2.12+ | Client Kafka Python |
| **Psycopg2** | 2.9+ | Driver PostgreSQL |
| **TimescaleDB** | Latest | Base de donnÃ©es temporelle |
| **Apache Kafka** | 7.3+ | Broker de messages |
| **Docker** | - | Conteneurisation |

---

## ğŸ“ˆ Kafka Topics

### Topic Principal : `capteurs-data`

**Format des messages :**
```json
{
  "capteur_id": "SENSOR_001",
  "timestamp": "2025-11-01T14:30:00Z",
  "data": {
    "temperature": 22.5,
    "humidite": 65.0,
    "humidite_sol": 45.0,
    "niveau_ph": 6.8,
    "luminosite": 850.0
  }
}
```

### Commandes Kafka Utiles

```bash
# Lister les topics
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --list

# CrÃ©er le topic
docker exec -it kafka kafka-topics --create --bootstrap-server localhost:9092 \
  --topic capteurs-data --partitions 3 --replication-factor 1

# Consommer les messages (debug)
docker exec -it kafka kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic capteurs-data --from-beginning
```

---

## ğŸ” Monitoring et Logs

### Logs du Microservice

```bash
# Logs en temps rÃ©el
docker logs -f ingestion-capteurs

# DerniÃ¨res 100 lignes
docker logs --tail 100 ingestion-capteurs
```

### MÃ©triques Disponibles

```http
GET /metrics
```

Retourne :
- Nombre de requÃªtes traitÃ©es
- Latence moyenne
- Erreurs de validation
- Messages Kafka publiÃ©s

---

## ğŸ§ª Tests

### Tests Unitaires

```bash
# Installer les dÃ©pendances de test
pip install pytest pytest-asyncio httpx

# Lancer les tests
pytest tests/ -v

# Avec couverture
pytest tests/ --cov=app --cov-report=html
```

### Tests d'IntÃ©gration

```bash
# Tester l'API
curl -X POST http://localhost:8000/api/v1/capteurs/ingest \
  -H "Content-Type: application/json" \
  -d '{
    "capteur_id": "TEST_001",
    "timestamp": "2025-11-01T14:30:00Z",
    "temperature": 22.5,
    "humidite_sol": 45.0
  }'
```

---

## ğŸš¨ Gestion des Erreurs

### Codes d'Erreur

| Code | Description |
|------|-------------|
| 400 | DonnÃ©es invalides ou manquantes |
| 500 | Erreur interne du serveur |
| 503 | Service temporairement indisponible (Kafka/DB) |

### Exemple de RÃ©ponse d'Erreur

```json
{
  "error": "ValidationError",
  "message": "Le champ 'capteur_id' est obligatoire",
  "details": {
    "field": "capteur_id",
    "received": null
  },
  "timestamp": "2025-11-01T14:30:00Z"
}
```

---

## ğŸ“ Bonnes Pratiques

### Validation des DonnÃ©es
- âœ… Toujours valider les timestamps (format ISO 8601)
- âœ… VÃ©rifier les plages de valeurs (tempÃ©rature, pH, etc.)
- âœ… Rejeter les donnÃ©es avec `capteur_id` manquant

### Performance
- ğŸš€ Utiliser l'endpoint `/batch` pour les envois multiples
- ğŸš€ Limiter la frÃ©quence d'envoi (recommandÃ© : 1 mesure/15 secondes)
- ğŸš€ Configurer les pools de connexion DB correctement

### SÃ©curitÃ©
- ğŸ”’ Utiliser HTTPS en production
- ğŸ”’ ImplÃ©menter l'authentification API (JWT tokens)
- ğŸ”’ Valider et nettoyer toutes les entrÃ©es

---

## ğŸ”„ Workflow de Traitement

```
1. RÃ©ception de donnÃ©es (API REST)
           â†“
2. Validation Pydantic
           â†“
3. Enrichissement (timestamp serveur si manquant)
           â†“
4. VÃ©rification de cohÃ©rence
           â†“
5. Stockage TimescaleDB (asynchrone)
           â†“
6. Publication Kafka
           â†“
7. Transmission au microservice de PrÃ©traitement
```

---

## ğŸ¤ Contribution

Ce microservice fait partie du projet Agrotrace. Pour contribuer :

1. Fork le repository
2. CrÃ©er une branche feature (`git checkout -b feature/amelioration`)
3. Commit les changements (`git commit -m 'Ajout fonctionnalitÃ© X'`)
4. Push vers la branche (`git push origin feature/amelioration`)
5. Ouvrir une Pull Request

---

## ğŸ“ Support

Pour toute question ou problÃ¨me :
- ğŸ“§ Email : support@agrotrace.com
- ğŸ“– Documentation : [Wiki du projet](https://github.com/Rzn-Mohamed/Ingestion-pipeline-Agrotrace/wiki)
- ğŸ› Issues : [GitHub Issues](https://github.com/Rzn-Mohamed/Ingestion-pipeline-Agrotrace/issues)

---

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.


---

**Version :** 1.0.0  
**DerniÃ¨re mise Ã  jour :** Novembre 2025  
**Auteur :** Rzn-Mohamed
